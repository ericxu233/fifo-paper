\section{Evaluation}
\label{sec:evaluation}

To evaluate FIFO initialization and the associated optimizations, we implemented a cycle-accurate simulator of our CGRA architecture with FIFO initialization support. We compared the performance of our approach against a baseline CGRA architecture without FIFO initialization across a suite of benchmarks with varying loop-carried dependence characteristics.

\subsection{Experimental Setup}
\label{subsec:exp-setup}
Our simulator models a CGRA with 8x8 processing elements (PEs), each equipped with a FIFO of depth 8 by default. The latency of floating-point PE operations is described in Table~\ref{tab:pe-latency}. Other operations such as integer arithmetic and logic operations are set to have a latency of 1 cycle. The inter-PE communication latency is set to 1 cycle. 

Our CGRA assumes an elastic dataflow execution model along with data streaming. Data is streamed onto and out of the CGRA from DRAM at a constant rate of 16 words per cycle. The latency to access DRAM is set to 400 cycles by default which dictates the initial latency to start streaming data as well as the stall cycles when FIFOs fill up due to pipeline imbalance.

To model the runtime overhead of the peeled-loop iterations introduced by the optimizations in Section \ref{sec:optimization}, we assume that each peeled iteration incurs an additional overhead of 3 cyles times the number of operations in the target loop body.

\begin{table}[h]
\centering
\caption{PE Operation Latencies (in cycles)}
\label{tab:pe-latency}
\begin{tabular}{|l|c|}
\hline
\textbf{Operation} & \textbf{Latency} \\
\hline
fadd & 3 \\
fsub & 3 \\
fmul & 4 \\
fdiv & 6 \\
fcomp & 2 \\
exp & 6 \\
\hline
\end{tabular}
\end{table}

The baseline CGRA architecture is identical except that it does not support FIFO initialization. Therefore, loop-carried dependences must be handled using the PHI node approach.

The benchmark suite consists of various benchmarks found in scientific computing, machine learning, and signal processing domains. We take some of the benchmarks from Polybench \cite{pouchet2012polybench} and some from prior works on accelerating linear recurrences \cite{maleki2018automatic}. Table~\ref{tab:benchmarks} summarizes the benchmarks used in our evaluation.

\begin{table}[h]
\centering
\caption{Benchmark Suite}
\label{tab:benchmarks}
\begin{tabular}{|l|l|l|}
\hline
\textbf{Benchmark} & \textbf{Category} & \textbf{Description} \\
\hline
\multicolumn{3}{|c|}{\textit{Linear Recurrences}} \\
\hline
ema & Signal Proc. & Exponential moving average \\
exp\_decay & Signal Proc. & Exponential decay filter \\
hp\_filter & Signal Proc. & High-pass filter \\
momentum\_sgd & ML & SGD with momentum update \\
weighted\_avg & Signal Proc. & Weighted sum recurrence \\
\hline
\multicolumn{3}{|c|}{\textit{Reductions}} \\
\hline
gemm & Linear Algebra & Matrix multiplication \\
mvt & Linear Algebra & Matrix-vector product \\
gaussian\_cdf & Statistics & Gaussian CDF computation \\
sep & Physics & Spring energy profile \\
fd & Physics & Fluid dynamics simulation \\
\hline
\multicolumn{3}{|c|}{\textit{Stencils}} \\
\hline
conv2d & Image Proc. & 3$\times$3 2D convolution \\
conv5x5 & Image Proc. & 5$\times$5 2D convolution \\
jacobi2d & Numerical & Jacobi 2D stencil \\
\hline
\end{tabular}
\end{table}

\subsection{Reductions and Linear Recurrences}
\label{subsec:overall-speedup}

% Load pre-processed data from artifacts (generated by scripts/generate_plot_data.py)
\pgfplotstableread[col sep=comma]{artifacts/throughput_comparison.csv}\throughputdata

\begin{figure}[t]
\centering
\begin{tikzpicture}
\begin{axis}[
    ybar,
    width=\columnwidth,
    height=6cm,
    bar width=4pt,
    ylabel={Throughput (iter/cycle)},
    symbolic x coords={ema, exp_decay, hp_filter, momentum_sgd, weighted_avg, gaussian_cdf, gemm, mvt, sep, fd},
    xtick=data,
    xticklabels={ema, exp\_decay, hp\_filter, momentum\_sgd, weighted\_avg, gaussian\_cdf, gemm, mvt, sep, fd},
    x tick label style={rotate=45, anchor=east, font=\footnotesize},
    ymin=0,
    ymax=1.1,
    legend style={at={(0.5,1.02)}, anchor=south, legend columns=3, font=\scriptsize},
    legend cell align={left},
    enlarge x limits=0.08,
]

% Baseline (PHI-only)
\addplot[fill=gray!60, draw=black] table[x=testname, y=baseline] {\throughputdata};

% FIFO Initialization
\addplot[fill=blue!60, draw=black] table[x=testname, y=fifo_init] {\throughputdata};

% FIFO Init + Lookahead
\addplot[fill=red!60, draw=black] table[x=testname, y=lookahead] {\throughputdata};

\legend{Baseline (PHI-only), FIFO Init, FIFO Init + Lookahead}
\end{axis}
\end{tikzpicture}
\caption{Throughput comparison across benchmarks for reductions and linear recurrences. Default configuration: FIFO depth=8, streaming latency=400 cycles, MEDIUM\_DATASET.}
\label{fig:throughput-comparison}
\end{figure}

Figure~\ref{fig:throughput-comparison} presents the throughput comparison across our benchmark suite for reductions and linear recurrences. We compare three configurations: (1) the baseline PHI-only implementation without FIFO initialization, (2) FIFO initialization without lookahead expansion, and (3) FIFO initialization with lookahead expansion enabled.

The results demonstrate that FIFO initialization alone provides modest throughput improvements, ranging from 1.1$\times$ to 1.4$\times$ over the baseline. This improvement comes from eliminating the PHI node overhead and reducing the DFG size. However, the most significant gains are achieved when combining FIFO initialization with lookahead expansion, which enables effective pipelining of the loop-carried dependence chain. With lookahead expansion, throughput improves dramatically---up to 12.7$\times$ for \texttt{exp\_decay} and over 9$\times$ on average across all benchmarks.

