\section{Introduction}
For decades, Moore's Law has driven consistent improvements in general-purpose computing devices by scaling transistor density and frequency. However, we are now approaching the physical and economic limits of this scaling. Nonetheless, due to emerging applications, such as large language models and cloud computing continue to demand performance, power, and efficiency. Therefore, both industry and academia are increasingly focused on pursuing new architecture-level innovations and enhanced software enablement. 

Coarse-Grained Reconfigurable Arrays (CGRAs) are one such architecture of interest that was first proposed in the 1990s and has been gaining in popularity recently \cite{ragheb2024cgra}. CGRAs are well-suited for exploiting fine-grained spatial parallelism in applications, offering superior energy efficiency compared to general-purpose, instruction-based processors such as CPUs and GPUs, while still preserving a high degree of programmability compared to special-purpose ASICs. Recent proposed and commercialized CGRA architectures show performance per watt of speed up in the range of 100x to 1000x compared to similar category general purpose CPUs \cite{riptide, monza}. 

A CGRA is typically a two-dimensional grid of processing elements (PEs) that are reconfigurable and interconnected by programmable links. There are two types of CGRAs, which are temporal CGRAs and spatial CGRAs. Their difference lies within their PE configuration. Temporal CGRAs' PEs can be reconfigured every cycle, while spatial CGRAs' PEs can only be configured once at the start of execution.  In this work, we will focus on spatial CGRAs because they offer even more energy efficiency and are simpler to program \cite{liu2019survey}.

CGRAs are programmed by first translating a high-level programming language (typically C) into dataflow graphs (DFG) and then mapping them through placement and routing onto the physical device for execution. Programmers usually annotate parallel for-loops for acceleration on CGRAs since these loops dominate the application's execution time \cite{liu2019survey}. 

Given the relatively simple spatial architecture of CGRAs, supporting loop-carried dependences remains a significant challenge. In particular, loop-carried dependences pose a challenge for CGRAs to efficiently handle and execute. Loop-carried dependences frequently appear in key worloads such as ML/AI, scientific computing and digital signal processing, etc.

Most temporal CGRAs only support a subset of loop-carried dependences and rely on the mapper to do temporal scheduling to ensure the dependences are respected \cite{karunaratne2017hycube, rau1994iterative}. For spatial CGRAs, recent work has proposed enabling support for loop-carried dependences through specialized hardware semantics \cite{riptide, torng2021ultra}. However, these efforts primarily focus on improving the programmability of spatial CGRAs at the expense of consuming more PE resources, and as a result, remain inefficient in practice. Furthermore, recurrences, which are a special type of loop-carried dependence, acts as a performance-limiting factor for both temporal and spatial CGRAs \cite{torng2021ultra, rau1994iterative}.

In this work, we introduce FIFO initialization. A novel hardware mechanism for spatial elastic CGRAs that can efficiently support loop-carried dependences. It is achieved by adding minimal hardware overhead that enables FIFOs in the CGRA PEs to be programmed at configuration time to initialize values required by a loop-carried dependence. FIFO initialization offers two key advantages over existing approaches. First, it eliminates the need for additional PEs to support loop-carried dependences, thereby preserving scarce PE resources for computation. Second, relying solely on software optimization techniques, it enables fast execution of recurrences that prior work could only achieve through additional and more complicated hardware.

We also instantiate compiler support for FIFO initialization, where it is capable of identifying loop-carried dependences and applying transformations to lower them into FIFO initialization constructs. Furthermore, the compiler will identify opportunities where FIFO initialization can be leveraged for optimizations. This includes enabling fast recurrences on our CGRA through an optimization technique known as look-ahead \cite{parhi1989pipeline2}.

In summary, we make the following contributions:
\begin{itemize}
    \item We present FIFO initialization, a novel hardware mechanism to efficiently support loop-carried dependences on spatial elastic CGRAs.
    \item We illustrate the use of FIFO initialization in three important computations that give use to loop-carried dependences: reductions, recurrences, and data reuse.
    \item We built a compiler capable of leveraging FIFO initialization and its optimizations.
\end{itemize}
